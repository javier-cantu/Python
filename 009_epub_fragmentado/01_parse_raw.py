# === Wikipedia/Text to Sentence-per-Line Preprocessor ===
#
# üìò Descripci√≥n:
# Este script est√° dise√±ado para procesar archivos de texto largos (por ejemplo, novelas o art√≠culos de Wikipedia)
# y transformarlos en un formato donde cada oraci√≥n aparece en una l√≠nea separada.
# Las l√≠neas vac√≠as o los marcadores de fin de p√°rrafo se indican con `===`.
#
# ‚úÖ Caracter√≠sticas Mejoradas:
# - Detecta y extrae t√≠tulos, subt√≠tulos y jerarqu√≠as de secciones (#level1:, #level2:, etc.).
# - Soporta la inclusi√≥n de im√°genes con l√≠neas como: @img: archivo.jpg | descripci√≥n.
# - **Manejo robusto de puntos suspensivos:**
#   - Normaliza patrones inusuales (ej. ". . . .", "....", "...") a un formato est√°ndar de "..." .
#   - Protege los puntos suspensivos para que NO sean interpretados como finales de oraci√≥n.
# - **Manejo avanzado de abreviaciones:**
#   - Protege abreviaciones comunes (ej. "e.g.", "Mr.", "Dr.", "etc.") para evitar divisiones incorrectas.
#   - Manejo de puntos en listas numeradas (ej. "1. Item") para evitar divisiones.
#   - **Nuevo: Protecci√≥n de acr√≥nimos con puntos (ej. "O.W.L.", "U.S.A.") para mantenerlos intactos.**
# - Limpia referencias textuales como `[1]` y `[citation needed]`.
#
# ‚ö†Ô∏è Limitaciones:
# - Puede no detectar oraciones si no terminan expl√≠citamente en un punto (`.`), signo de interrogaci√≥n (`?`) o exclamaci√≥n (`!`).
# - El √©xito de la protecci√≥n de abreviaturas y acr√≥nimos depende de la lista predefinida; es posible que se necesiten a√±adir m√°s.
#
# üõ† C√≥mo extender:
# - Agrega m√°s abreviaciones, t√≠tulos o acr√≥nimos a las listas correspondientes seg√∫n sea necesario.
# - Utiliza expresiones regulares m√°s avanzadas para contextos de texto muy espec√≠ficos.
#
# === CONFIGURACI√ìN ===

import re

input_file = "raw_wikipedia.txt"
output_file = "input.txt"

# === Cargar y limpiar texto ===
with open(input_file, "r", encoding="utf-8") as f:
    raw_lines = [line.strip() for line in f if line.strip()]

output_lines = []
current_levels = {}

# === Procesar cada l√≠nea ===
for line in raw_lines:

    # --- T√≠tulos y subt√≠tulos ---
    if line.lower().startswith("title:"):
        output_lines.append("title: " + line[6:].strip())

    elif line.lower().startswith("subtitle:"):
        output_lines.append("subtitle: " + line[9:].strip())

    # --- Jerarqu√≠a de secciones ---
    elif line.lower().startswith("#level"):
        match = re.match(r"#level(\d+):\s*(.+)", line, re.IGNORECASE)
        if match:
            level = int(match.group(1))
            title = match.group(2).strip()
            current_levels[level] = title

            for key in list(current_levels.keys()):
                if key > level:
                    del current_levels[key]

            hierarchy = " > ".join(current_levels[i] for i in sorted(current_levels))
            output_lines.append(f"[{hierarchy}]")
            output_lines.append("===")

    # --- Im√°genes ---
    elif line.lower().startswith("@img:"):
        output_lines.append(line)
        output_lines.append("===")

    # --- P√°rrafos normales ---
    else:
        # Limpiar referencias y caracteres invisibles primero
        line = re.sub(r"\[\d+\]", "", line)
        line = re.sub(r"\[citation needed\]", "", line, flags=re.IGNORECASE)
        line = line.replace('\u200b', '').replace('\u200c', '')

        # --- COMIENZO DEL PROCESAMIENTO AVANZADO DE TEXTO ---

        # PASO 0: Proteger n√∫meros de lista (ej. "1.", "2.", etc.)
        # Esto debe hacerse ANTES de cualquier otra normalizaci√≥n o protecci√≥n de puntos.
        line = re.sub(r'^\s*(\d+)\.\s*', r'\1__NUMDOT__ ', line)

        # PASO 1: Normalizar patrones de puntos suspensivos *antes* de protegerlos.
        line = re.sub(r'\.\s*\.\s*\.\s*\.', '...', line)  # Normaliza ". . . ." a "..."
        line = re.sub(r'\.{4,}', '...', line)  # Normaliza "...." a "..."
        line = re.sub(r'\u2026', '...', line)  # Normaliza el car√°cter de ellipsis Unicode (‚Ä¶) a "..."

        # PASO 2: Proteger abreviaciones, t√≠tulos Y ACR√ìNIMOS.
        # Estas deben ser protegidas *antes* de los puntos suspensivos gen√©ricos.
        # Abrevaciones comunes (con punto)
        abbreviations = {
            "c.": "c__DOT__",
            "e.g.": "e__DOT__g__DOT__",
            "i.e.": "i__DOT__e__DOT__",
            "etc.": "etc__DOT__",
            "a. C.": "a__DOT__C__DOT__",
            "d. C.": "d__DOT__C__DOT__",
            "P.M.": "P__DOT__M__DOT__",
            "A.M.": "A__DOT__M__DOT__"
        }
        for k, v in abbreviations.items():
            line = line.replace(k, v)

        # T√≠tulos como Mr., Dr., etc.
        titles = {
            "Mr.": "Mr__DOT__",
            "Mrs.": "Mrs__DOT__",
            "Ms.": "Ms__DOT__",
            "Dr.": "Dr__DOT__",
            "Prof.": "Prof__DOT__",
            "Sr.": "Sr__DOT__",
            "Jr.": "Jr__DOT__",
            "St.": "St__DOT__"
        }
        for k, v in titles.items():
            line = line.replace(k, v)

        # NUEVO: Acr√≥nimos con puntos (ej. O.W.L., U.S.A.)
        # Aseg√∫rate de listar aqu√≠ los acr√≥nimos exactos como aparecen en tu texto
        acronyms = {
            "O.W.L.": "O__DOT__W__DOT__L__DOT__",
            "U.S.A.": "U__DOT__S__DOT__A__DOT__",
            # Agrega m√°s acr√≥nimos con puntos aqu√≠ si los encuentras en tu texto
        }
        # Es importante reemplazar de la forma m√°s larga a la m√°s corta para evitar problemas
        # con acr√≥nimos anidados (ej. "U.S.A." antes que "U.S.").
        for k, v in sorted(acronyms.items(), key=lambda item: len(item[0]), reverse=True):
            line = line.replace(k, v)

        # PASO 3: Proteger los puntos suspensivos normalizados
        line = re.sub(r"\s*\.\s*\.\s*\.\s*", " [ELLIPSIS] ", line)

        # Normalizar espacio despu√©s de punto/signo de interrogaci√≥n/exclamaci√≥n si hay may√∫scula (ayuda a dividir)
        line = re.sub(r'([.!?])\s*([A-Z√Å√â√ç√ì√ö√ë])', r'\1 \2', line)

        # Separar en oraciones
        sentences = re.split(r'(?<=[.!?])\s+', line)

        # PASO 4: Restaurar abreviaciones, t√≠tulos, acr√≥nimos y los puntos suspensivos.
        restored_sentences = []
        for s in sentences:
            # Restaurar abreviaciones comunes
            for k, v in abbreviations.items():
                s = s.replace(v, k)

            # Restaurar t√≠tulos
            for k, v in titles.items():
                s = s.replace(v, k)

            # Restaurar acr√≥nimos
            for k, v in sorted(acronyms.items(), key=lambda item: len(item[0]), reverse=True):
                s = s.replace(v, k)
            
            # Restaurar el placeholder de ellipsis
            s = s.replace("[ELLIPSIS]", "...")

            # Restaurar puntos en n√∫meros de lista
            s = re.sub(r'(\d+)__NUMDOT__\s*', r'\1. ', s)

            # Eliminar espacios en blanco al inicio y al final de la oraci√≥n.
            restored_sentences.append(s.strip())

        # Agregar al output
        for sentence in restored_sentences:
            if sentence:
                output_lines.append(sentence.strip())

        output_lines.append("===")

# === Guardar resultado ===
with open(output_file, "w", encoding="utf-8") as f:
    f.write("\n".join(output_lines))

print(f"‚úÖ Done. Output saved to {output_file}")