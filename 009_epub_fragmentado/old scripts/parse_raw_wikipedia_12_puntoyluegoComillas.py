# === Wikipedia/Text to Sentence-per-Line Preprocessor ===
#
# üìò Descripci√≥n:
# Este script est√° dise√±ado para procesar archivos de texto largos (por ejemplo, novelas o art√≠culos de Wikipedia)
# y transformarlos en un formato donde cada oraci√≥n aparece en una l√≠nea separada.
# Las l√≠neas vac√≠as o los marcadores de fin de p√°rrafo se indican con `===`.
#
# ‚úÖ Caracter√≠sticas Mejoradas:
# - Detecta y extrae t√≠tulos, subt√≠tulos y jerarqu√≠as de secciones (#level1:, #level2:, etc.).
# - Soporta la inclusi√≥n de im√°genes con l√≠neas como: @img: archivo.jpg | descripci√≥n.
# - **Manejo robusto de puntos suspensivos:**
# ¬† - Normaliza patrones inusuales (ej. ". . . .", "....", "...") a un formato est√°ndar de "..." .
# ¬† - Protege los puntos suspensivos para que NO sean interpretados como finales de oraci√≥n.
# - **Manejo avanzado de abreviaciones:**
# ¬† - Protege abreviaciones comunes (ej. "e.g.", "Mr.", "Dr.", "etc.") para evitar divisiones incorrectas.
# ¬† - Manejo de puntos en listas numeradas (ej. "1. Item") para evitar divisiones.
# ¬† - Protecci√≥n de acr√≥nimos con puntos (ej. "O.W.L.", "U.S.A.") para mantenerlos intactos.
# - **MEJORA: Manejo de oraciones que terminan con puntuaci√≥n seguida de comillas o corchetes (ej. `."` o `.]`).**
# ¬† - Ahora estas secuencias permanecen unidas a la oraci√≥n a la que pertenecen.
# - **NUEVO: Protecci√≥n de iniciales en nombres (ej. "Lawrence H. Keeley").**
# - Limpia referencias textuales como `[1]` y `[citation needed]`.
#
# ‚ö†Ô∏è Limitaciones:
# - El √©xito de la protecci√≥n de abreviaturas y acr√≥nimos depende de la lista predefinida; es posible que se necesiten a√±adir m√°s.
#
# üõ† C√≥mo extender:
# - Agrega m√°s abreviaciones, t√≠tulos o acr√≥nimos a las listas correspondientes seg√∫n sea necesario.
# - Utiliza expresiones regulares m√°s avanzadas para contextos de texto muy espec√≠ficos.
#
# === CONFIGURACI√ìN ===

import re

input_file = "raw_wikipedia.txt"
output_file = "input.txt"

# === Cargar y limpiar texto ===
with open(input_file, "r", encoding="utf-8") as f:
    raw_lines = [line.strip() for line in f if line.strip()]

output_lines = []
current_levels = {}

# === Procesar cada l√≠nea ===
for line in raw_lines:

    # --- T√≠tulos y subt√≠tulos ---
    if line.lower().startswith("title:"):
        output_lines.append("title: " + line[6:].strip())

    elif line.lower().startswith("subtitle:"):
        output_lines.append("subtitle: " + line[9:].strip())

    # --- Jerarqu√≠a de secciones ---
    elif line.lower().startswith("#level"):
        match = re.match(r"#level(\d+):\s*(.+)", line, re.IGNORECASE)
        if match:
            level = int(match.group(1))
            title = match.group(2).strip()
            current_levels[level] = title

            for key in list(current_levels.keys()):
                if key > level:
                    del current_levels[key]

            hierarchy = " > ".join(current_levels[i] for i in sorted(current_levels))
            output_lines.append(f"[{hierarchy}]")
            output_lines.append("===")

    # --- Im√°genes ---
    elif line.lower().startswith("@img:"):
        output_lines.append(line)
        output_lines.append("===")

    # --- P√°rrafos normales ---
    else:
        # Limpiar referencias y caracteres invisibles primero
        line = re.sub(r"\[\d+\]", "", line)
        line = re.sub(r"\[citation needed\]", "", line, flags=re.IGNORECASE)
        line = line.replace('\u200b', '').replace('\u200c', '')

        # --- COMIENZO DEL PROCESAMIENTO AVANZADO DE TEXTO ---

        # PASO 0: Proteger n√∫meros de lista (ej. "1.", "2.", etc.)
        # Esto debe hacerse ANTES de cualquier otra normalizaci√≥n o protecci√≥n de puntos.
        line = re.sub(r'^\s*(\d+)\.\s*', r'\1__NUMDOT__ ', line)

        # PASO 1: Normalizar patrones de puntos suspensivos *antes* de protegerlos.
        line = re.sub(r'\.\s*\.\s*\.\s*\.', '...', line)  # Normaliza ". . . ." a "..."
        line = re.sub(r'\.{4,}', '...', line)  # Normaliza "...." a "..."
        line = re.sub(r'\u2026', '...', line)  # Normaliza el car√°cter de ellipsis Unicode (‚Ä¶) a "..."

        # PASO 2: Proteger abreviaciones, t√≠tulos Y ACR√ìNIMOS.
        # Estas deben ser protegidas *antes* de los puntos suspensivos gen√©ricos.

        # Protege iniciales en nombres (ej. "H. Keeley")
        # Busca una letra may√∫scula simple seguida de un punto, un espacio y otra palabra que empieza con may√∫scula.
        # Aseg√∫rate de que no sea parte de una abreviaci√≥n ya listada (como U.S.).
        line = re.sub(r'([A-Z])\.\s+([A-Z√Å√â√ç√ì√ö√ë][a-zA-Z√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë]+)', r'\1__INITIALDOT__ \2', line)

        # Abrevaciones comunes (con punto)
        abbreviations = {
            "c.": "c__DOT__",
            "e.g.": "e__DOT__g__DOT__",
            "i.e.": "i__DOT__e__DOT__",
            "etc.": "etc__DOT__",
            "a. C.": "a__DOT__C__DOT__",
            "d. C.": "d__DOT__C__DOT__",
            "P.M.": "P__DOT__M__DOT__",
            "A.M.": "A__DOT__M__DOT__",
            "P.S.": "P__DOT__S__DOT__",
            "U.S.": "U__DOT__S__DOT__"
        }
        for k, v in abbreviations.items():
            line = line.replace(k, v)

        # T√≠tulos como Mr., Dr., etc.
        titles = {
            "Mr.": "Mr__DOT__",
            "Mrs.": "Mrs__DOT__",
            "Ms.": "Ms__DOT__",
            "Dr.": "Dr__DOT__",
            "Prof.": "Prof__DOT__",
            "Sr.": "Sr__DOT__",
            "Jr.": "Jr__DOT__",
            "St.": "St__DOT__",
        }
        for k, v in titles.items():
            line = line.replace(k, v)

        # Acr√≥nimos con puntos (ej. O.W.L., U.S.A.)
        # Es importante reemplazar de la forma m√°s larga a la m√°s corta para evitar problemas
        # con acr√≥nimos anidados (ej. "U.S.A." antes que "U.S.").
        acronyms = {
            "O.W.L.": "O__DOT__W__DOT__L__DOT__", # Harry Potter
            "D.A.": "D__DOT__A__DOT__", # Harry Potter
            "N.E.W.T.": "N__DOT__E__DOT__W__DOT__T__DOT__", # Harry Potter
            "S.P.E.W.": "S__DOT__P__DOT__E__DOT__W__DOT__", # Harry Potter
            "R.A.B." : "R__DOT__A__DOT__B__DOT__", # Harry Potter
            "U.S.A.": "U__DOT__S__DOT__A__DOT__", # Demo
        }
        for k, v in sorted(acronyms.items(), key=lambda item: len(item[0]), reverse=True):
            line = line.replace(k, v)

        # PASO 3: Proteger los puntos suspensivos normalizados
        line = re.sub(r"\s*\.\s*\.\s*\.\s*", " [ELLIPSIS] ", line)

        # MEJORA CLAVE: Marcar finales de oraci√≥n complejos para una divisi√≥n precisa.
        # Capturamos la puntuaci√≥n y las opcionales comillas/corchetes, seguidos de cualquier espacio.
        # La condici√≥n (?=[A-Z√Å√â√ç√ì√ö√ë]|$) asegura que solo marcamos finales de oraci√≥n v√°lidos
        # (seguidos de una may√∫scula o fin de l√≠nea).
        line = re.sub(r'([.!?])(["‚Äù\'\]]?)\s*(?=[A-Z√Å√â√ç√ì√ö√ë]|$)', r'\1\2__SPLIT_MARKER__', line)


        # Separar en oraciones utilizando el marcador √∫nico
        # Strip() para eliminar espacios en blanco resultantes de la divisi√≥n
        sentences = [s.strip() for s in line.split('__SPLIT_MARKER__') if s.strip()]


        # PASO 4: Restaurar abreviaciones, t√≠tulos, acr√≥nimos y los puntos suspensivos.
        restored_sentences = []
        for s in sentences:
            # Restaurar abreviaciones comunes
            for k, v in abbreviations.items():
                s = s.replace(v, k)

            # Restaurar t√≠tulos
            for k, v in titles.items():
                s = s.replace(v, k)

            # Restaurar acr√≥nimos
            for k, v in sorted(acronyms.items(), key=lambda item: len(item[0]), reverse=True):
                s = s.replace(v, k)
            
            # Restaurar iniciales en nombres
            s = re.sub(r'__INITIALDOT__\s*', r'. ', s) 

            # Restaurar el placeholder de ellipsis
            s = s.replace("[ELLIPSIS]", "...")

            # Restaurar puntos en n√∫meros de lista
            s = re.sub(r'(\d+)__NUMDOT__\s*', r'\1. ', s)

            # Eliminar espacios en blanco al inicio y al final de la oraci√≥n.
            restored_sentences.append(s.strip())

        # Agregar al output
        for sentence in restored_sentences:
            if sentence:
                output_lines.append(sentence.strip())

        output_lines.append("===")

# === Guardar resultado ===
with open(output_file, "w", encoding="utf-8") as f:
    f.write("\n".join(output_lines))

print(f"‚úÖ Done. Output saved to {output_file}")
